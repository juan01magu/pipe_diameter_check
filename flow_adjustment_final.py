# -*- coding: utf-8 -*-
"""Flow_adjustment_Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ArJkwDMPfDHw-DgCDBrKpdqTihOEhP7v
"""

import numpy as np # type: ignore
import pandas as pd # type: ignore
import matplotlib.pyplot as plt # type: ignore
import os
import math
import re
from scipy.optimize import fsolve # type: ignore

#from google.colab import drive
#drive.mount('/content/drive')

filename = 'TC_TM_004_0036.csv'
#filename = 'TC_TM_006_0030.csv'
#filename = 'TC_TM_036_0027_2.csv'

match = re.search(r"_(\d+\.\d+|\d+)\.csv$", filename)
D = float(match.group(1)) if match else None

pd.set_option('display.float_format', '{:.9f}'.format)  # Show up to 8 decimal places

# Define the columns names
original_columns = ['level', 'velocity', 'flow']
# Now you can load your data from 'your_data_file.csv'
data = pd.read_csv(filename, names=original_columns)
# Display the updated DataFrame
print("This is the head of the original data:")
print(data.head())


# # WE ARE WORKING WITH FEET, FT/S and CFS


# Delete the blank spaces
data.dropna(subset=['level'], inplace=True)
print(data['level'].isnull())

# Plot level in a separate figure
plt.figure(figsize=(10, 7))
plt.plot(data.index, data['level'], label='Level', color='b', alpha=0.7)
plt.xlim(000 ,105120)
plt.ylim(-0.1,3)
plt.xlabel('Time (Index)')
plt.ylabel('Level')
plt.title('Original Level')
plt.legend()
plt.grid()
plt.show()

# FLOW CALCULATION FUNCTION
def calculate_flow(D, d, v): # Calculate the cross-sectional area of water in a pipe.

    # D: Pipe diameter
    # d: Water depth
    if d > D:
        raise ValueError("Water depth (D) cannot be greater than pipe diameter (d).")

    r = D / 2  # Radius of the pipe
    if d == 0:
        return 0  # No water in the pipe
    elif d == D:
        return v * math.pi * (r**2)  # Full pipe (circle area)

    # Ensure acos() input is within valid range [-1, 1]
    value = (D - 2*d) / D
    value = max(-1, min(1, value))  # Clamp value to prevent math domain error

    theta = 2 * math.acos(value)

    # Compute the area using the formula
    A = (D**2 / 8) * (theta - math.sin(theta))

    Q = A * v  # Flow rate in cfs
    #Q1 = Q / 1.547 # As we are working with mgd
    return Q

# WHITE NOISE ADDED TO THE WHOLE LEVEL
mean = 0
std = round(np.random.uniform(0,0.3),2)  # Random std between 0 and 1
std=0.05
white_noise = np.random.normal(mean, std, size=len(data))

adjustment = []
data_wn = data.copy()
data_wn['level'] += white_noise

for i in range(len(data)):
  if data_wn.loc[i, 'level'] >= 0:
    adjustment.append(0)
  else:
    adjustment.append(abs(data_wn.loc[i, 'level']))
    data_wn.loc[i, 'level'] = 0

adjustment = np.array(adjustment)
print(adjustment)

adjusted_noise = white_noise + adjustment
new_std = round(np.std(adjusted_noise, ddof=1), 4)  # Use ddof=1 for sample std deviation

print('The previous std was:', std, 'and the new standard deviation of the noise is:', new_std)

plt.figure(figsize=(10, 7))
plt.plot(data_wn.index, data_wn['level'], label='Level', color='b', alpha=0.7)
plt.xlim(000 ,105120)
plt.ylim(-0.1,3)
plt.xlabel('Time (Index)')
plt.ylabel('Level')
plt.title('Level with white noise')
plt.legend()
plt.grid()
plt.show()

# V = Cslope * R
def calculate_c_slope(V, D, d):

  c_offset = 0.02
  fraction = (D - 2*(d-c_offset)) / D
  # Clip fraction to prevent math domain errors
  fraction = np.clip(fraction, -1, 1)

  sqrt_term = np.sqrt(1 - fraction**2)
  arc_cos_term = 2 * np.arccos(fraction)

  R = (D / 8) * (1 - (2 * fraction * sqrt_term) / arc_cos_term) # Hydraulic radius

  c_slope = (V / (R ** (2/3))).mean()

  return c_slope


V_Day_1 = data_wn['velocity'][:288]
d_Day_1 = data_wn['level'][:288]

if d_Day_1.max() < 0.85*D:
# Calculate c_slope for all rows
  c_slope = calculate_c_slope(V_Day_1, D, d_Day_1)
  print(c_slope)
else:
  print("Error: First day has surcharge data")

# Create the 'c_slope' column and assign the mean value to all rows
data_wn['c_slope'] = c_slope

# Verify the result (optional)
print(data_wn[['c_slope']].head())  # Show the first few rows

# LEVEL OFFSET ADDED AT A RANDOM INDEX
# Neither in the first nor in the last 10 percent of the data
#random_index = np.random.randint(int(0.1*len(data)), int(0.9*len(data)))
random_index = np.random.randint(int(0.1*len(data)), int(0.9*len(data)))
data_of = data_wn.copy()
offset = round(np.random.uniform(0, 5 * std), 3)  # Random offset between 0 and 3 * std
data_of.loc[random_index:, 'level'] += offset

print(data_of.iloc[random_index - 4 : random_index + 4])
print('\nThe offset is:', offset)
print('The index where the offset is applied is:', random_index)

# PLOT New level with noise and offset

# Plot new level in a separate figure
plt.figure(figsize=(10, 7))
plt.plot(data_of.index, data_of['level'], label='New level', color='b', alpha=0.7)
#plt.xlim(random_index-500 ,random_index+500)
plt.xlim(0, 105120)
#plt.ylim(-0.1,3)
plt.xlabel('Time (Index)')
plt.ylabel('Level')
plt.title('New Level')
plt.legend()
plt.grid()
plt.show()

# Check that level >= 0
negative_values = data_of[data_of['level'] < 0]
if not negative_values.empty:
    print(negative_values)
else:
    print("No negative values")

# NEW FLOW
data_of['new_flow'] = data_of.apply(lambda row: calculate_flow(D/12, row['level'], row['velocity']), axis = 1)

print(data_of.iloc[random_index - 4 : random_index + 4])

# Plot all Q (new_flow)
plt.figure(figsize=(9, 6))
plt.plot(data_of.index, data_of['new_flow'], label='Flow', color='b', alpha=0.7)
plt.ylim(-0.1,3)
plt.xlabel('Time (Index)')
plt.ylabel('FLOW')
plt.title('New flow')
plt.legend()
plt.grid()
plt.show()

# Plot the Q zoomed to its maximum value
max_Q_idx = data_of['new_flow'].idxmax()
plt.figure(figsize=(9, 6))
plt.plot(data_of.index, data_of['new_flow'], label='Flow', color='b', alpha=0.7)
plt.xlim(max_Q_idx - 1000, max_Q_idx + 1000)
plt.ylim(-0.1,3)
plt.xlabel('Time (Index)')
plt.ylabel('FLOW')
plt.title('New flow')
plt.legend()
plt.grid()
plt.show()

# Scattergraph of the Q zoomed to its maximum value
data_sct_level = data_of['level'][max_Q_idx - 1000: max_Q_idx + 1000]
data_sct_velocity = data_of['velocity'][max_Q_idx - 1000: max_Q_idx + 1000]
plt.figure(figsize=(9, 6))
plt.plot(data_sct_level, data_sct_velocity, marker='o', linestyle='None', alpha=0.7)
plt.xlabel('Level')
plt.ylabel('Velocity')
plt.title('Scattergraph')
plt.legend()
plt.grid()
plt.show()

# Without perturbation

# Plot the Q zoomed to the perturbation index
plt.figure(figsize=(8, 5))
plt.plot(data.index, data['flow'], label='Flow', color='b', alpha=0.7)
plt.xlim(random_index - 1000, random_index + 1000)
plt.ylim(-0.1,3)
plt.xlabel('Time (Index)')
plt.ylabel('FLOW')
plt.title('Original Flow')
plt.legend()
plt.grid()
plt.show()

# Scattergraph of the Q zoomed to the perturbation index
data_sct_level = data['level'][random_index - 1000: random_index + 1000]
data_sct_velocity = data['velocity'][random_index - 1000: random_index + 1000]
plt.figure(figsize=(8, 5))
plt.plot(data_sct_level, data_sct_velocity, marker='o', linestyle='None', alpha=0.7)
plt.xlabel('Level')
plt.ylabel('Velocity')
plt.title('Scattergraph')
plt.legend()
plt.grid()
plt.show()

# With perturbation
# Plot the Q zoomed to the perturbation index
plt.figure(figsize=(8, 5))
plt.plot(data_of.index, data_of['new_flow'], label='Flow', color='b', alpha=0.7)
plt.xlim(random_index - 1000, random_index + 1000)
#plt.ylim(-0.1,3)
plt.xlabel('Time (Index)')
plt.ylabel('FLOW')
plt.title('Original Flow')
plt.legend()
plt.grid()
plt.show()

# Scattergraph of the Q zoomed to the perturbation index
data_sct_level = data_of['level'][random_index - 1000: random_index + 1000]
data_sct_velocity = data_of['velocity'][random_index - 1000: random_index + 1000]
plt.figure(figsize=(8, 5))
plt.plot(data_sct_level, data_sct_velocity, marker='o', linestyle='None', alpha=0.7)
plt.xlabel('Level')
plt.ylabel('Velocity')
plt.title('Scattergraph')
plt.legend()
plt.grid()
plt.show()

# C_OFFSET
dt = data_of.copy()

def calculate_c_offset(V, Cslope, D, d):
    def equation(c_offset):
        fraction = (D - 2 * (d - c_offset)) / D
        fraction = np.clip(fraction, -1, 1)  # Ensure it's within valid range
        arc_cos_term = 2 * np.arccos(fraction)
        sqrt_term = np.sqrt(1 - fraction**2)
        R = (D / 8) * (1 - (2 * fraction * sqrt_term) / arc_cos_term)
        return R**(2/3) - (V / Cslope)

    c_offset_initial_guess = 0.02  # Adjust if necessary
    c_offset_solution = fsolve(equation, c_offset_initial_guess)
    return c_offset_solution[0]

dt['c_offset'] = dt.apply(lambda row: np.nan if row['level'] > D * 0.85 else calculate_c_offset(row['velocity'], row['c_slope'], D, row['level']), axis=1)

#To have all columns together in the same row
pd.set_option('display.max_columns', None)  # Show all columns
pd.set_option('display.width', 1000)  # Prevent line wrapping

print(dt.iloc[random_index - 8 : random_index + 8])

# C_OFFSET VS TIME
plt.figure(figsize=(8, 5))
plt.plot(dt.index, dt['c_offset'], label='c_offset', color='b')
#plt.xlim(random_index - 1000, random_index + 1000)
plt.ylabel('c_offset')
plt.grid()



# Weekly calculation (previous and next)

def compare_means_week(dt, column):
    n = len(dt)
    cutoff = int(0.1 * n)

    rolling_mean_prev = dt[column].rolling(window=288*7, min_periods=1).apply(np.nanmean, raw=True)
    rolling_mean_next = dt[column][::-1].rolling(window=288*7, min_periods=1).apply(np.nanmean, raw=True)[::-1]

    rolling_median_prev = dt[column].rolling(window=288*7, min_periods=1).apply(np.nanmedian, raw=True)
    rolling_median_next = dt[column][::-1].rolling(window=288*7, min_periods=1).apply(np.nanmedian, raw=True)[::-1]

    mean_difference = np.abs(rolling_mean_next - rolling_mean_prev)
    median_difference = np.abs(rolling_median_next - rolling_median_prev)
    off_mean = (mean_difference > 0.001) & (dt.index >= cutoff) & (dt.index <= int(0.9 * n))
    off_median = (median_difference > 0.005) & (dt.index >= cutoff) & (dt.index <= int(0.9 * n))

    return pd.DataFrame({
        'Previous_mean': rolling_mean_prev,
        'Next_mean': rolling_mean_next,
        'Mean Difference': mean_difference,
        'Previous_median': rolling_median_prev,
        'Next_median': rolling_median_next,
        'Median Difference': median_difference,
        'c_offset': dt['c_offset'],
        'Off_detected_mean': off_mean,
        'Off_detected_median': off_median
    })
#To have all columns together in the same row
pd.set_option('display.max_columns', None)  # Show all columns
pd.set_option('display.width', 1000)  # Prevent line wrapping

dt_result_week = compare_means_week(dt, 'c_offset')

plt.figure(figsize=(8, 5))
plt.plot(dt_result_week.index,dt_result_week['Mean Difference'], label='Mean Difference', color='b')
#plt.xlim(random_index-2016 , random_index+2016)
#plt.ylim(-0.1,8)
plt.xlabel('Time')
plt.ylabel('Mean Difference')
plt.title('Weekly Offset Mean Difference')
plt.legend()
plt.grid()
plt.show()

# Results with mean
detected_mean = int(dt_result_week.loc[dt_result_week['Off_detected_mean'] == True]['Mean Difference'].idxmax())
print("Results of the mean method for a previous and next week calculation:\n")
print("The random index where the offset has been applied is: ", random_index)
print("The system's answer is: ", detected_mean)

# Code to convert the index to a date and a time in the year
def index_to_datetime(index):

    if not isinstance(index, int) or index < 0 or index > 105119:
        return None  # Handle out-of-range indices

    start_date = pd.to_datetime('2023-10-11 00:00')
    time_delta = pd.Timedelta(minutes=5)

    date_time = start_date + time_delta * index
    return date_time


def format_datetime(datetime_obj):
    """Formats a datetime object into a user-friendly string."""
    if datetime_obj is None:
        return "Invalid Index"
    return datetime_obj.strftime("%Y-%m-%d %H:%M")

print()
print("The random time where the offset has been applied is: ", format_datetime(index_to_datetime(random_index)))
print("The system's answer is: ", format_datetime(index_to_datetime(detected_mean)))
print()
print("The offset that has been added is: ", dt_result_week.loc[detected_mean, 'Mean Difference'])


plt.figure(figsize=(8, 5))
plt.plot(dt_result_week.index,dt_result_week['Mean Difference'], label='Mean Difference', color='b')
#plt.xlim(random_index-2016 , random_index+2016)
#plt.ylim(-0.1,8)
plt.xlabel('Time')
plt.ylabel('Median Difference')
plt.title('Weekly Offset Median Difference')
plt.legend()
plt.grid()
plt.show()

# Results with median: median works better in cases when there has been a storm or a peak in the level. Because the mean is affected in those cases and not the median. However with low levels is not that accurate.
# In other cases the mean works better
detected_median = int(dt_result_week.loc[dt_result_week['Off_detected_median'] == True]['Median Difference'].idxmax())
print("Results of the median method for a previous and next week calculation:\n")
print("The random index where the offset has been applied is: ", random_index)
print("The system's answer is: ", detected_median)
print()
print("The random time where the offset has been applied is: ", format_datetime(index_to_datetime(random_index)))
print("The system's answer is: ", format_datetime(index_to_datetime(detected_mean)))
print()
print("The offset that has been added is: ", dt_result_week.loc[detected_mean, 'Median Difference'])


# Daily calculation (previous and next)

def compare_means_day(dt, column):
    n = len(dt)
    cutoff = int(0.1 * n)

    rolling_mean_prev = dt[column].rolling(window=288, min_periods=1).apply(np.nanmean, raw=True)
    rolling_mean_next = dt[column][::-1].rolling(window=288, min_periods=1).apply(np.nanmean, raw=True)[::-1]

    rolling_median_prev = dt[column].rolling(window=288, min_periods=1).apply(np.nanmedian, raw=True)
    rolling_median_next = dt[column][::-1].rolling(window=288, min_periods=1).apply(np.nanmedian, raw=True)[::-1]

    mean_difference = np.abs(rolling_mean_next - rolling_mean_prev)
    median_difference = np.abs(rolling_median_next - rolling_median_prev)
    off_mean = (mean_difference > 0.001) & (dt.index >= cutoff) & (dt.index <= int(0.9 * n))
    off_median = (median_difference > 0.005) & (dt.index >= cutoff) & (dt.index <= int(0.9 * n))

    return pd.DataFrame({
        'Previous_mean': rolling_mean_prev,
        'Next_mean': rolling_mean_next,
        'Mean Difference': mean_difference,
        'Previous_median': rolling_median_prev,
        'Next_median': rolling_median_next,
        'Median Difference': median_difference,
        'c_offset': dt['c_offset'],
        'Off_detected_mean': off_mean,
        'Off_detected_median': off_median
    })
#To have all columns together in the same row
pd.set_option('display.max_columns', None)  # Show all columns
pd.set_option('display.width', 1000)  # Prevent line wrapping

dt_result_day = compare_means_day(dt, 'c_offset')
#print(dt_result.iloc[random_index - 10 : random_index + 10])

plt.figure(figsize=(8, 5))
plt.plot(dt_result_day.index,dt_result_day['Mean Difference'], label='Mean Difference', color='b')
#plt.xlim(random_index-2016 , random_index+2016)
#plt.ylim(-0.1,8)
plt.xlabel('Time')
plt.ylabel('Mean Difference')
plt.title('Daily Offset Mean Difference')
plt.legend()
plt.grid()
plt.show()

# Results with mean
detected_mean = int(dt_result_day.loc[dt_result_day['Off_detected_mean'] == True]['Mean Difference'].idxmax())
print("Results of the mean method for a previous and next day calculation:\n")
print("The random index where the offset has been applied is: ", random_index)
print("The system's answer is: ", detected_mean)
print()
print("The random time where the offset has been applied is: ", format_datetime(index_to_datetime(random_index)))
print("The system's answer is: ", format_datetime(index_to_datetime(detected_mean)))
print()
print("The offset that has been added is: ", dt_result_day.loc[detected_mean, 'Mean Difference'])

plt.figure(figsize=(8, 5))
plt.plot(dt_result_day.index,dt_result_day['Median Difference'], label='Median Difference', color='b')
#plt.xlim(random_index-2016 , random_index+2016)
#plt.ylim(-0.1,8)
plt.xlabel('Time')
plt.ylabel('Median Difference')
plt.title('Daily Offset Median Difference')
plt.legend()
plt.grid()
plt.show()

# Results with median: median works better in cases when there has been a storm or a peak in the level. Because the mean is affected in those cases and not the median. However with low levels is not that accurate.
# In other cases the mean works better
detected_median = int(dt_result_day.loc[dt_result_day['Off_detected_median'] == True]['Median Difference'].idxmax())
print("Results of the median method for a previous and next day calculation:\n")
print("The random index where the offset has been applied is: ", random_index)
print("The system's answer is: ", detected_median)
print()
print("The random time where the offset has been applied is: ", format_datetime(index_to_datetime(random_index)))
print("The system's answer is: ", format_datetime(index_to_datetime(detected_median)))
print()
print("The offset that has been added is: ", dt_result_day.loc[detected_mean, 'Median Difference'])

## Hourly calculation (previous and next)

# Hourly calculation (previous and next)

def compare_means_hour(dt, column):
    n = len(dt)
    cutoff = int(0.1 * n)

    rolling_mean_prev = dt[column].rolling(window=24, min_periods=1).apply(np.nanmean, raw=True)
    rolling_mean_next = dt[column][::-1].rolling(window=24, min_periods=1).apply(np.nanmean, raw=True)[::-1]

    rolling_median_prev = dt[column].rolling(window=24, min_periods=1).apply(np.nanmedian, raw=True)
    rolling_median_next = dt[column][::-1].rolling(window=24, min_periods=1).apply(np.nanmedian, raw=True)[::-1]

    mean_difference = np.abs(rolling_mean_next - rolling_mean_prev)
    median_difference = np.abs(rolling_median_next - rolling_median_prev)
    off_mean = (mean_difference > 0.001) & (dt.index >= cutoff) & (dt.index <= int(0.9 * n))
    off_median = (median_difference > 0.005) & (dt.index >= cutoff) & (dt.index <= int(0.9 * n))

    return pd.DataFrame({
        'Previous_mean': rolling_mean_prev,
        'Next_mean': rolling_mean_next,
        'Mean Difference': mean_difference,
        'Previous_median': rolling_median_prev,
        'Next_median': rolling_median_next,
        'Median Difference': median_difference,
        'c_offset': dt['c_offset'],
        'Off_detected_mean': off_mean,
        'Off_detected_median': off_median
    })
#To have all columns together in the same row
pd.set_option('display.max_columns', None)  # Show all columns
pd.set_option('display.width', 1000)  # Prevent line wrapping

dt_result_hour = compare_means_hour(dt, 'c_offset')
#print(dt_result.iloc[random_index - 10 : random_index + 10])

plt.figure(figsize=(8, 5))
plt.plot(dt_result_hour.index,dt_result_hour['Mean Difference'], label='Mean Difference', color='b')
#plt.xlim(random_index-2016 , random_index+2016)
#plt.ylim(-0.1,8)
plt.xlabel('Time')
plt.ylabel('Mean Difference')
plt.title('Hourly Offset Mean Difference')
plt.legend()
plt.grid()
plt.show()

# Results with mean
detected_mean = int(dt_result_hour.loc[dt_result_hour['Off_detected_mean'] == True]['Mean Difference'].idxmax())
print("Results of the mean method for a previous and next hour calculation:\n")
print("The random index where the offset has been applied is: ", random_index)
print("The system's answer is: ", detected_mean)
print()
print("The random time where the offset has been applied is: ", format_datetime(index_to_datetime(random_index)))
print("The system's answer is: ", format_datetime(index_to_datetime(detected_mean)))
print()
print("The offset that has been added is: ", dt_result_hour.loc[detected_mean, 'Mean Difference'])

plt.figure(figsize=(8, 5))
plt.plot(dt_result_hour.index,dt_result_hour['Median Difference'], label='Median Difference', color='b')
#plt.xlim(random_index-500 , random_index+500)
#plt.ylim(-0.1,8)
plt.xlabel('Time')
plt.ylabel('Median Difference')
plt.title('Hourly Offset Median Difference')
plt.legend()
plt.grid()
plt.show()

# Results with median: median works better in cases when there has been a storm or a peak in the level. Because the mean is affected in those cases and not the median. However with low levels is not that accurate.
# In other cases the mean works better
detected_median = int(dt_result_hour.loc[dt_result_hour['Off_detected_median'] == True]['Median Difference'].idxmax())
print("Results of the median method for a previous and next hour calculation:\n")
print("The random index where the offset has been applied is: ", random_index)
print("The system's answer is: ", detected_median)
print()
print("The random time where the offset has been applied is: ", format_datetime(index_to_datetime(random_index)))
print("The system's answer is: ", format_datetime(index_to_datetime(detected_median)))
print()
print("The offset that has been added is: ", dt_result_hour.loc[detected_mean, 'Median Difference'])

plt.figure(figsize=(8, 5))
plt.plot(dt_result_week.index,dt_result_week['Mean Difference'], label='Weekly Mean Difference', color='b')
plt.plot(dt_result_day.index,dt_result_day['Mean Difference'], label='Daily Mean Difference', color='r')
plt.plot(dt_result_hour.index,dt_result_hour['Mean Difference'], label='Hourly Mean Difference', color='g')
plt.xlim(random_index-2016 , random_index+2016)
#plt.ylim(-0.1,8)
plt.xlabel('Time')
plt.ylabel('Median Difference')
plt.title('Weekly Offset Median Difference')
plt.legend()
plt.grid()
plt.show()



"""## EXTRA"""

# File to store results
log_file = "/content/drive/My Drive/detection_log_4weeks.csv"

def track_detection(random_index, detected_mean, detected_median, offset, std, filename):
    """Tracks if the system correctly detected the offset and logs the results."""

    # Check if detection is within the Â±576 range
    correctly_found = abs(detected_mean - random_index) <= 576
    correctly_found_med = abs(detected_median - random_index) <= 576

    # Compute SNR
    snr = round(offset / std, 3) if std != 0 else np.nan

    # Create a dictionary with results
    result = {
        "Random_Index": random_index,
        "Detected Mean": detected_mean,
        'Detected Median': detected_median,
        "Correct Mean": correctly_found,
        "Correct Median": correctly_found_med,
        "SNR": snr,
        "Offset": offset,
        "STD": std,
        "Filename": filename
    }

    # Convert to DataFrame
    df_result = pd.DataFrame([result])

    # Check if log file exists, append or create new
    if os.path.exists(log_file):
        df_result.to_csv(log_file, mode='a', header=False, index=False)
    else:
        df_result.to_csv(log_file, mode='w', header=True, index=False)

    print(f"Logged: {result}")

track_detection(random_index, detected_mean, detected_median, offset, new_std, filename)

def calculate_chunk_means(data, chunk_size):


  n_chunks = len(data) // chunk_size  # Integer division to get the number of full chunks
  chunk_means = []

  for i in range(n_chunks):
      start = i * chunk_size
      end = (i + 1) * chunk_size
      chunk = data['c_offset'][start:end]

      # Handle potential NaNs within a chunk (e.g., if a chunk has all NaNs)
      chunk_mean = np.nanmean(chunk) # Use numpy to ignore nans if they are present
      chunk_means.append(chunk_mean)

  return pd.Series(chunk_means, index=range(1, n_chunks + 1))  # Index by chunk number

daily_means = calculate_chunk_means(dt, 288)
weekly_means = calculate_chunk_means(dt, 288 * 7)
monthly_means = calculate_chunk_means(dt, 288 * 30)

plt.figure(figsize=(10, 4))
plt.plot(daily_means.index, daily_means.values, marker='o', linestyle='-', color='blue') # Added markers
plt.xlim(60 , 70)
plt.xlabel('Chunk Number (Day)')
plt.ylabel('Mean c_offset')
plt.title('Mean c_offset per 288 Data Points (Day)')
#plt.xticks(np.arange(60, 70 + 1, step=10)) #Show only each 10 days
plt.xticks(np.arange(0, len(daily_means) + 1, step=10)) #Show only each 10 days
plt.grid(True)
plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 4))
plt.plot(weekly_means.index, weekly_means.values, marker='o', linestyle='-', color='red') # Added markers
#plt.ylim(-1 , 1)
plt.xlabel('Chunk Number (Week)')
plt.ylabel('Mean c_offset')
plt.title('Mean c_offset per 288*7 Data Points (Week)')
plt.xticks(np.arange(1, len(weekly_means) + 1, step=5)) #Show only each 10 days
plt.grid(True)
plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 4))
plt.plot(monthly_means.index, monthly_means.values, marker='o', linestyle='-', color='green') # Added markers
#plt.ylim(-1 , 1)
plt.xlabel('Chunk Number (Month)')
plt.ylabel('Mean c_offset')
plt.title('Mean c_offset per 288*30 Data Points (Month)')
plt.xticks(np.arange(1, len(monthly_means) + 1, step=1)) #Show only each 10 days
plt.grid(True)
plt.tight_layout()
plt.show()

def calculate_chunk_medians(data, chunk_size):


    n_chunks = len(data) // chunk_size  # Integer division to get the number of full chunks
    chunk_medians = []

    for i in range(n_chunks):
        start = i * chunk_size
        end = (i + 1) * chunk_size
        chunk = data['c_offset'][start:end]

        # Handle potential NaNs within a chunk (e.g., if a chunk has all NaNs)
        chunk_median = np.nanmedian(chunk) # Use numpy to ignore nans if they are present
        chunk_medians.append(chunk_median)

    return pd.Series(chunk_medians, index=range(1, n_chunks + 1))  # Index by chunk number

daily_medians = calculate_chunk_medians(dt, 288)
weekly_medians = calculate_chunk_medians(dt, 288 * 7)
monthly_medians = calculate_chunk_medians(dt, 288 * 30)

plt.figure(figsize=(10,4))
plt.plot(daily_medians.index, daily_medians.values, marker='o', linestyle='-', color='blue') # Added markers
plt.xlim(190, 210)
plt.xlabel('Chunk Number (Day)')
plt.ylabel('Median c_offset')
plt.title('Median c_offset per 288 Data Points (Day)')
#plt.xticks(np.arange(190, 210 + 1, step=1)) #Show only each 10 days
plt.xticks(np.arange(0, len(daily_medians) + 1, step=10)) #Show only each 10 days
plt.grid(True)
plt.tight_layout()
plt.show()

plt.figure(figsize=(10,4))
plt.plot(weekly_medians.index, weekly_medians.values, marker='o', linestyle='-', color='red') # Added markers
#plt.ylim(-1 , 1)
plt.xlabel('Chunk Number (Week)')
plt.ylabel('Median c_offset')
plt.title('Median c_offset per 288*7 Data Points (Week)')
plt.xticks(np.arange(1, len(weekly_medians) + 1, step=5)) #Show only each 10 days
plt.grid(True)
plt.tight_layout()
plt.show()

plt.figure(figsize=(10,4))
plt.plot(monthly_medians.index, monthly_medians.values, marker='o', linestyle='-', color='green') # Added markers
#plt.ylim(-1 , 1)
plt.xlabel('Chunk Number (Month)')
plt.ylabel('Median c_offset')
plt.title('Median c_offset per 288*30 Data Points (Month)')
plt.xticks(np.arange(1, len(monthly_medians) + 1, step=1)) #Show only each 10 days
plt.grid(True)
plt.tight_layout()
plt.show()
